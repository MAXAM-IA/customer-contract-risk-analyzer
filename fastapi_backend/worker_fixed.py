import time
import json
import pandas as pd
from pathlib import Path
import logging
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
import base64
import httpx
import os

# Cargar variables de entorno desde .env si existe
try:
    from dotenv import load_dotenv
    load_dotenv()
    logger = logging.getLogger(__name__)
    logger.info("‚úÖ Variables de entorno cargadas desde .env")
except ImportError:
    logger = logging.getLogger(__name__)
    logger.info("‚ö†Ô∏è  python-dotenv no instalado, usando variables de entorno del sistema")

# Configurar logging para worker
logger = logging.getLogger(__name__)

def analizar_pregunta(pregunta, seccion, pdf_bytes, pdf_filename="documento.pdf"):
    """
    Analiza una pregunta usando Gemini LLM y adjunta el PDF (en bytes) como contexto multimodal.
    Devuelve un dict con 'Respuesta' y 'Riesgo'.
    """
    logger.info(f"üß† ANALIZANDO PREGUNTA: '{pregunta[:50]}...' | Secci√≥n: {seccion} | Archivo: {pdf_filename}")
    
    try:
        api_key = os.getenv("GOOGLE_API_KEY", "")
        if not api_key:
            logger.error("‚ùå GOOGLE_API_KEY no est√° configurada")
            return {
                "Respuesta": "Error: GOOGLE_API_KEY no configurada",
                "Riesgo": "Alto"
            }
        
        logger.info(f"üîë API Key configurada correctamente")
        
        LLM_MODEL = "gemini-2.5-flash-preview-05-20"
        logger.info(f"ü§ñ Inicializando modelo: {LLM_MODEL}")
        
        llm = ChatGoogleGenerativeAI(
            model=LLM_MODEL,
            temperature=0,
            max_tokens=None,
            max_retries=2,
            http_client=httpx.Client(verify=False),
            google_api_key=api_key
        )
        logger.info(f"‚úÖ Modelo inicializado correctamente")

        # Convertir PDF a base64 para Gemini
        logger.info(f"üìÑ Convirtiendo PDF a base64 (tama√±o: {len(pdf_bytes)} bytes)")
        pdf_base64 = base64.b64encode(pdf_bytes).decode()
        logger.info(f"‚úÖ PDF convertido a base64")
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", """Eres un asistente legal experto en an√°lisis de contratos. Analiza el documento PDF adjunto y responde de forma clara y precisa a la pregunta del usuario. 

Al final de tu respuesta, eval√∫a el nivel de riesgo legal bas√°ndote en los siguientes criterios:
- ALTO: Cl√°usulas que pueden generar responsabilidades significativas, terminaci√≥n unilateral, penalizaciones severas, t√©rminos ambiguos que favorecen a la contraparte, ausencia de protecciones importantes.
- MEDIO: T√©rminos que requieren atenci√≥n pero no representan riesgos inmediatos, cl√°usulas est√°ndar con posibles mejoras.
- BAJO: T√©rminos favorables o neutros, cl√°usulas est√°ndar de la industria, protecciones adecuadas.

Termina tu respuesta con una l√≠nea que indique claramente: "RIESGO: [ALTO/MEDIO/BAJO]" """),
            ("human", [
                {"type": "text", "text": f"Secci√≥n: {seccion}\nPregunta: {pregunta}"},
                {"type": "image_url", "image_url": {"url": f"data:application/pdf;base64,{pdf_base64}"}}
            ])
        ])
        
        logger.info(f"üìù Enviando consulta al LLM...")
        chain = prompt | llm | StrOutputParser()
        respuesta_llm = chain.invoke({})
        logger.info(f"‚úÖ Respuesta recibida del LLM (longitud: {len(respuesta_llm)} caracteres)")
        
        # Extraer el nivel de riesgo de la respuesta del LLM
        riesgo = "Medio"  # Valor por defecto
        
        # Buscar tanto "RISK:" (ingl√©s) como "RIESGO:" (espa√±ol) para mayor compatibilidad
        if "RISK:" in respuesta_llm.upper() or "RIESGO:" in respuesta_llm.upper():
            lineas = respuesta_llm.split('\n')
            for linea in lineas:
                linea_upper = linea.upper()
                if "RISK:" in linea_upper or "RIESGO:" in linea_upper:
                    # Mapear valores en ingl√©s y espa√±ol
                    if any(word in linea_upper for word in ["HIGH", "ALTO"]):
                        riesgo = "Alto"
                    elif any(word in linea_upper for word in ["LOW", "BAJO"]):
                        riesgo = "Bajo"
                    elif any(word in linea_upper for word in ["MEDIUM", "MEDIO"]):
                        riesgo = "Medio"
                    elif any(word in linea_upper for word in ["NOT EVALUATED", "NO EVALUADO", "SIN EVALUAR"]):
                        riesgo = "Sin evaluar"
                    break
        
        logger.info(f"üéØ Riesgo evaluado: {riesgo}")
        
        # Limpiar la respuesta removiendo la l√≠nea de riesgo para que no aparezca duplicada
        lineas_respuesta = respuesta_llm.split('\n')
        respuesta_final = '\n'.join([linea for linea in lineas_respuesta if not any(
            word in linea.upper() for word in ['RISK:', 'RIESGO:']
        )])
        
        resultado = {
            "Respuesta": respuesta_final.strip(),
            "Riesgo": riesgo
        }
        
        logger.info(f"‚úÖ An√°lisis completado exitosamente")
        return resultado
        
    except Exception as e:
        logger.error(f"‚ùå ERROR EN AN√ÅLISIS: {str(e)}", exc_info=True)
        return {
            "Respuesta": f"Error al procesar la pregunta: {str(e)}",
            "Riesgo": "Alto"
        }

def analizar_documento(contrato_path, preguntas_path, progreso_path):
    """Funci√≥n principal que analiza un documento con todas las preguntas de manera as√≠ncrona"""
    logger.info(f"üöÄ INICIANDO AN√ÅLISIS AS√çNCRONO")
    logger.info(f"üìÅ Contrato: {contrato_path}")
    logger.info(f"üìã Preguntas: {preguntas_path}")
    logger.info(f"üìä Progreso: {progreso_path}")
    
    try:
        # Leer las preguntas del archivo Excel
        logger.info(f"üìñ Leyendo preguntas desde: {preguntas_path}")
        df_preguntas = pd.read_excel(preguntas_path)
        preguntas = df_preguntas.to_dict('records')
        logger.info(f"‚úÖ {len(preguntas)} preguntas cargadas exitosamente")
        
        # Leer el PDF del contrato
        logger.info(f"üìÑ Leyendo contrato desde: {contrato_path}")
        with open(contrato_path, "rb") as f:
            pdf_bytes = f.read()
        logger.info(f"‚úÖ Contrato le√≠do exitosamente ({len(pdf_bytes)} bytes)")
        
        # Inicializar el archivo de progreso
        logger.info(f"üìä Inicializando archivo de progreso")
        progreso_data = {
            "estado": "en_progreso",
            "progreso": 0,
            "total_preguntas": len(preguntas),
            "resultados": [],
            "fecha_inicio": time.strftime("%Y-%m-%d %H:%M:%S"),
            "preguntas_originales": preguntas
        }
        
        with open(progreso_path, "w", encoding="utf-8") as f:
            json.dump(progreso_data, f, indent=2, ensure_ascii=False)
        logger.info(f"‚úÖ Archivo de progreso inicializado")
        
        # Procesar cada pregunta
        resultados = []
        for idx, pregunta_data in enumerate(preguntas):
            logger.info(f"üìù Procesando pregunta {idx+1}/{len(preguntas)}")
            
            pregunta = pregunta_data.get("Pregunta", "")
            seccion = pregunta_data.get("Secci√≥n", "Sin secci√≥n")
            
            # Analizar la pregunta
            resultado = analizar_pregunta(pregunta, seccion, pdf_bytes, contrato_path.name)
            
            # A√±adir informaci√≥n de la pregunta al resultado
            resultado.update({
                "Pregunta": pregunta,
                "Secci√≥n": seccion,
            })
            
            resultados.append(resultado)
            
            # Actualizar progreso
            progreso_data["progreso"] = idx + 1
            progreso_data["resultados"] = resultados
            progreso_data["fecha_modificacion"] = time.strftime("%Y-%m-%d %H:%M:%S")
            
            with open(progreso_path, "w", encoding="utf-8") as f:
                json.dump(progreso_data, f, indent=2, ensure_ascii=False)
            
            logger.info(f"‚úÖ Pregunta {idx+1} completada")
        
        # Finalizar el an√°lisis
        progreso_data["estado"] = "completado"
        progreso_data["num_resultados"] = len(resultados)
        progreso_data["fecha_finalizacion"] = time.strftime("%Y-%m-%d %H:%M:%S")
        
        with open(progreso_path, "w", encoding="utf-8") as f:
            json.dump(progreso_data, f, indent=2, ensure_ascii=False)
        
        logger.info(f"üéâ AN√ÅLISIS COMPLETADO EXITOSAMENTE - {len(resultados)} preguntas procesadas")
        
    except Exception as e:
        logger.error(f"‚ùå ERROR EN AN√ÅLISIS: {str(e)}", exc_info=True)
        try:
            with open(progreso_path, "w", encoding="utf-8") as f:
                json.dump({
                    "estado": "error",
                    "resultados": [],
                    "error": str(e),
                    "fecha_error": time.strftime("%Y-%m-%d %H:%M:%S")
                }, f)
        except Exception as e2:
            logger.error(f"‚ùå ERROR AL GUARDAR ERROR: {str(e2)}")

def analizar_documento_con_preguntas_custom(contrato_path, preguntas_custom, progreso_path):
    """Analiza un documento con preguntas personalizadas proporcionadas por el usuario"""
    logger.info(f"üöÄ INICIANDO AN√ÅLISIS CON PREGUNTAS CUSTOM - {len(preguntas_custom)} preguntas")
    
    try:
        # Leer el PDF del contrato
        with open(contrato_path, "rb") as f:
            pdf_bytes = f.read()
        
        # Inicializar el archivo de progreso
        progreso_data = {
            "estado": "en_progreso",
            "progreso": 0,
            "total_preguntas": len(preguntas_custom),
            "resultados": [],
            "fecha_inicio": time.strftime("%Y-%m-%d %H:%M:%S"),
            "preguntas_originales": preguntas_custom
        }
        
        with open(progreso_path, "w", encoding="utf-8") as f:
            json.dump(progreso_data, f, indent=2, ensure_ascii=False)
        
        # Procesar cada pregunta
        resultados = []
        for idx, pregunta_data in enumerate(preguntas_custom):
            logger.info(f"üìù Procesando pregunta custom {idx+1}/{len(preguntas_custom)}")
            
            pregunta = pregunta_data.get("pregunta", "")
            seccion = pregunta_data.get("seccion", "Sin secci√≥n")
            
            # Analizar la pregunta
            resultado = analizar_pregunta(pregunta, seccion, pdf_bytes, contrato_path.name)
            
            # A√±adir informaci√≥n de la pregunta al resultado
            resultado.update({
                "Pregunta": pregunta,
                "Secci√≥n": seccion,
            })
            
            resultados.append(resultado)
            
            # Actualizar progreso
            progreso_data["progreso"] = idx + 1
            progreso_data["resultados"] = resultados
            progreso_data["fecha_modificacion"] = time.strftime("%Y-%m-%d %H:%M:%S")
            
            with open(progreso_path, "w", encoding="utf-8") as f:
                json.dump(progreso_data, f, indent=2, ensure_ascii=False)
        
        # Finalizar el an√°lisis
        progreso_data["estado"] = "completado"
        progreso_data["num_resultados"] = len(resultados)
        progreso_data["fecha_finalizacion"] = time.strftime("%Y-%m-%d %H:%M:%S")
        
        with open(progreso_path, "w", encoding="utf-8") as f:
            json.dump(progreso_data, f, indent=2, ensure_ascii=False)
        
        logger.info(f"‚úÖ AN√ÅLISIS CON PREGUNTAS CUSTOM COMPLETADO - {len(resultados)} preguntas procesadas")
        
    except Exception as e:
        logger.error(f"‚ùå ERROR EN AN√ÅLISIS CUSTOM: {str(e)}", exc_info=True)
        try:
            with open(progreso_path, "w", encoding="utf-8") as f:
                json.dump({
                    "estado": "error",
                    "resultados": [],
                    "error": str(e),
                    "fecha_error": time.strftime("%Y-%m-%d %H:%M:%S")
                }, f)
        except Exception as e2:
            logger.error(f"‚ùå ERROR AL GUARDAR ERROR: {str(e2)}")

def reanalizar_pregunta_individual_sobreescribir(contrato_path, pregunta_data, progreso_path):
    """
    Re-analiza una pregunta individual SOBREESCRIBIENDO el an√°lisis original.
    Actualiza √∫nicamente la pregunta especificada en el an√°lisis existente.
    """
    logger.info(f"üîÑ INICIANDO RE-AN√ÅLISIS INDIVIDUAL (SOBREESCRIBIR) - Pregunta: {pregunta_data.get('num_pregunta')}")
    
    try:
        # Leer el progreso original
        with open(progreso_path, "r", encoding="utf-8") as f:
            progreso_original = json.load(f)
        
        # Obtener el n√∫mero de pregunta a actualizar
        num_pregunta = pregunta_data.get("num_pregunta", 0)
        
        # Verificar que existe el resultado para esa pregunta
        if "resultados" not in progreso_original or len(progreso_original["resultados"]) <= num_pregunta:
            raise Exception(f"No existe resultado para la pregunta {num_pregunta}")
        
        # Leer el contrato
        with open(contrato_path, "rb") as f:
            pdf_bytes = f.read()
        
        # Analizar la nueva pregunta
        resultado = analizar_pregunta(
            pregunta_data["pregunta"], 
            pregunta_data["seccion"], 
            pdf_bytes, 
            contrato_path.name
        )
        
        # Actualizar solo la pregunta espec√≠fica en los resultados
        progreso_original["resultados"][num_pregunta].update({
            "Pregunta": pregunta_data["pregunta"],
            "Secci√≥n": pregunta_data["seccion"], 
            "Respuesta": resultado["Respuesta"],
            "Riesgo": resultado["Riesgo"],
            "reanalizado_en": time.strftime("%Y-%m-%d %H:%M:%S"),
            "tipo_reanalisis": "individual"
        })
        
        # Actualizar metadatos del an√°lisis
        progreso_original.update({
            "estado": "completado",
            "fecha_modificacion": time.strftime("%Y-%m-%d %H:%M:%S"),
            "ultima_pregunta_reanalizada": num_pregunta,
            "num_resultados": len(progreso_original["resultados"])
        })
        
        # Guardar el progreso actualizado
        with open(progreso_path, "w", encoding="utf-8") as f:
            json.dump(progreso_original, f, indent=2, ensure_ascii=False)
        
        logger.info(f"‚úÖ RE-AN√ÅLISIS INDIVIDUAL (SOBREESCRIBIR) COMPLETADO - Pregunta {num_pregunta} actualizada")
        
    except Exception as e:
        logger.error(f"‚ùå ERROR EN RE-AN√ÅLISIS INDIVIDUAL (SOBREESCRIBIR): {str(e)}", exc_info=True)
        try:
            # Actualizar solo el estado de error sin perder los datos existentes
            with open(progreso_path, "r", encoding="utf-8") as f:
                progreso_actual = json.load(f)
            
            progreso_actual.update({
                "estado": "error",
                "error": f"Error en re-an√°lisis individual: {str(e)}",
                "fecha_modificacion": time.strftime("%Y-%m-%d %H:%M:%S")
            })
            
            with open(progreso_path, "w", encoding="utf-8") as f:
                json.dump(progreso_actual, f, indent=2, ensure_ascii=False)
        except Exception as e2:
            logger.error(f"‚ùå ERROR AL GUARDAR ERROR: {str(e2)}")


def reanalizar_documento_global_sobreescribir(contrato_path, preguntas_editadas, progreso_path):
    """
    Re-analiza todas las preguntas SOBREESCRIBIENDO el an√°lisis original.
    Mantiene el mismo ID y archivo de progreso.
    """
    logger.info(f"üîÑ INICIANDO RE-AN√ÅLISIS GLOBAL (SOBREESCRIBIR) - {len(preguntas_editadas)} preguntas")
    
    try:
        # Leer el progreso original
        with open(progreso_path, "r", encoding="utf-8") as f:
            progreso_original = json.load(f)
        
        # Actualizar estado inicial
        progreso_original.update({
            "estado": "reanalisis_en_progreso",
            "fecha_modificacion": time.strftime("%Y-%m-%d %H:%M:%S"),
            "tipo_reanalisis": "global",
            "progreso": 0,
            "total_preguntas": len(preguntas_editadas)
        })
        
        # Limpiar resultados anteriores pero mantener metadatos
        progreso_original["resultados"] = []
        
        # Guardar estado inicial
        with open(progreso_path, "w", encoding="utf-8") as f:
            json.dump(progreso_original, f, indent=2, ensure_ascii=False)
        
        # Leer el contrato
        with open(contrato_path, "rb") as f:
            pdf_bytes = f.read()
        
        nuevos_resultados = []
        
        # Procesar cada pregunta editada
        for idx, pregunta_data in enumerate(preguntas_editadas):
            logger.info(f"üìù Procesando pregunta {idx+1}/{len(preguntas_editadas)}")
            
            # Analizar la pregunta
            resultado = analizar_pregunta(
                pregunta_data["pregunta"], 
                pregunta_data["seccion"], 
                pdf_bytes, 
                contrato_path.name
            )
            
            # A√±adir metadatos del re-an√°lisis
            resultado.update({
                "Pregunta": pregunta_data["pregunta"],
                "Secci√≥n": pregunta_data["seccion"],
                "reanalizado_en": time.strftime("%Y-%m-%d %H:%M:%S"),
                "tipo_reanalisis": "global"
            })
            
            nuevos_resultados.append(resultado)
            
            # Actualizar progreso intermedio
            progreso_original.update({
                "progreso": idx + 1,
                "resultados": nuevos_resultados,
                "fecha_modificacion": time.strftime("%Y-%m-%d %H:%M:%S")
            })
            
            with open(progreso_path, "w", encoding="utf-8") as f:
                json.dump(progreso_original, f, indent=2, ensure_ascii=False)
        
        # Finalizar el an√°lisis
        progreso_original.update({
            "estado": "completado",
            "progreso": len(preguntas_editadas),
            "num_resultados": len(nuevos_resultados),
            "fecha_modificacion": time.strftime("%Y-%m-%d %H:%M:%S"),
            "preguntas_originales": preguntas_editadas  # Guardar las preguntas usadas
        })
        
        # Guardar resultado final
        with open(progreso_path, "w", encoding="utf-8") as f:
            json.dump(progreso_original, f, indent=2, ensure_ascii=False)
        
        logger.info(f"‚úÖ RE-AN√ÅLISIS GLOBAL (SOBREESCRIBIR) COMPLETADO - {len(nuevos_resultados)} preguntas procesadas")
        
    except Exception as e:
        logger.error(f"‚ùå ERROR EN RE-AN√ÅLISIS GLOBAL (SOBREESCRIBIR): {str(e)}", exc_info=True)
        try:
            # Leer estado actual y actualizar con error
            with open(progreso_path, "r", encoding="utf-8") as f:
                progreso_actual = json.load(f)
            
            progreso_actual.update({
                "estado": "error",
                "error": f"Error en re-an√°lisis global: {str(e)}",
                "fecha_modificacion": time.strftime("%Y-%m-%d %H:%M:%S")
            })
            
            with open(progreso_path, "w", encoding="utf-8") as f:
                json.dump(progreso_actual, f, indent=2, ensure_ascii=False)
        except Exception as e2:
            logger.error(f"‚ùå ERROR AL GUARDAR ERROR: {str(e2)}")
